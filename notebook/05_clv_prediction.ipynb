{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba713b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load cleaned transactions\n",
    "df = pd.read_csv('data/clean/cleaned_online_retail.csv')\n",
    "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "\n",
    "# Compute revenue and drop any non-positive\n",
    "df['Revenue'] = df['Quantity'] * df['Price']\n",
    "df = df[df['Revenue'] > 0]\n",
    "\n",
    "print(\"Transactions:\", df.shape)\n",
    "\n",
    "from lifetimes.utils import summary_data_from_transaction_data\n",
    "\n",
    "clv_summary = summary_data_from_transaction_data(\n",
    "    transactions=df,\n",
    "    customer_id_col='Customer ID',\n",
    "    datetime_col='InvoiceDate',\n",
    "    monetary_value_col='Revenue',\n",
    "    observation_period_end=df['InvoiceDate'].max() + pd.Timedelta(days=1),\n",
    "    freq='W'   # use weeks for stability\n",
    ")\n",
    "\n",
    "print(clv_summary.head())\n",
    "# ensures freq>0 & monetary_value>0 by construction\n",
    "\n",
    "from lifetimes import BetaGeoFitter\n",
    "\n",
    "bgf = BetaGeoFitter(penalizer_coef=5)\n",
    "bgf.fit(\n",
    "    clv_summary['frequency'],\n",
    "    clv_summary['recency'],\n",
    "    clv_summary['T'],\n",
    "    tol=1e-6,\n",
    "    maxiter=200\n",
    ")\n",
    "print(\"BG/NBD parameters:\", bgf.params_)\n",
    "\n",
    "# Predict repeat transactions over next 4 weeks\n",
    "clv_summary['pred_purchases_4w'] = bgf.conditional_expected_number_of_purchases_up_to_time(\n",
    "    4,\n",
    "    clv_summary['frequency'],\n",
    "    clv_summary['recency'],\n",
    "    clv_summary['T']\n",
    ")\n",
    "print(clv_summary[['frequency','recency','T','pred_purchases_4w']].head())\n",
    "\n",
    "# Remove any customers whose average monetary_value is ≤ 0\n",
    "clv_summary = clv_summary[clv_summary['monetary_value'] > 0]\n",
    "print(\"Customers remaining after filter:\", clv_summary.shape[0])\n",
    "\n",
    "\n",
    "from lifetimes import GammaGammaFitter\n",
    "\n",
    "ggf = GammaGammaFitter(penalizer_coef=0.01)\n",
    "ggf.fit(\n",
    "    clv_summary['frequency'],\n",
    "    clv_summary['monetary_value']\n",
    ")\n",
    "print(\"Gamma–Gamma parameters:\", ggf.params_)\n",
    "\n",
    "# Predict each customer’s expected average profit\n",
    "clv_summary['exp_avg_profit'] = ggf.conditional_expected_average_profit(\n",
    "    frequency=clv_summary['frequency'],\n",
    "    monetary_value=clv_summary['monetary_value']\n",
    ")\n",
    "\n",
    "print(clv_summary[['monetary_value', 'exp_avg_profit']].head())\n",
    "# Calculate CLV for 4-week horizon\n",
    "clv_summary['clv_4w'] = ggf.customer_lifetime_value(\n",
    "    bgf,\n",
    "    clv_summary['frequency'],\n",
    "    clv_summary['recency'],\n",
    "    clv_summary['T'],\n",
    "    clv_summary['monetary_value'],\n",
    "    time=4,      # 4-week horizon\n",
    "    freq='W',    # weekly units\n",
    "    discount_rate=0.01\n",
    ")\n",
    "print(clv_summary[['pred_purchases_4w','exp_avg_profit','clv_4w']].head(15))\n",
    "# Save the CLV summary to a CSV file\n",
    "clv_summary.to_csv('data/clean/bg_nbd_clv_4w.csv')\n",
    "print(\"Saved BG/NBD + Gamma–Gamma CLV to data/clv/bg_nbd_clv_4w.csv\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load your CLV table\n",
    "clv_df = pd.read_csv('data/clean/bg_nbd_clv_4w.csv')\n",
    "\n",
    "# Compute key percentiles\n",
    "percentiles = clv_df['clv_4w'].quantile([0.5, 0.75, 0.9]).rename({0.5:'50th', 0.75:'75th', 0.9:'90th'})\n",
    "print(\"CLV 4-week percentiles:\")\n",
    "print(percentiles)\n",
    "# Find the CLV threshold for the top 1%\n",
    "cutoff_99 = clv_df['clv_4w'].quantile(0.99)\n",
    "\n",
    "# Filter to those top customers\n",
    "top_1pct = clv_df[clv_df['clv_4w'] >= cutoff_99].sort_values('clv_4w', ascending=False)\n",
    "\n",
    "print(f\"Top 1% cutoff = {cutoff_99:.2f}, number of top customers = {len(top_1pct)}\")\n",
    "print(top_1pct.head(10))   # show the very top 10\n",
    "\n",
    "# Load or reference your clustered RFM table\n",
    "rfm_clustered = pd.read_csv('data/rfm/rfm_clustered.csv', index_col=0, encoding='latin1')\n",
    "\n",
    "# Merge CLV and cluster label\n",
    "merged = clv_df.merge(\n",
    "    rfm_clustered[['Cluster']],\n",
    "    left_index=True, right_index=True,\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Compute average CLV by cluster\n",
    "cluster_clv = merged.groupby('Cluster')['clv_4w'].agg(['mean','median','count']).rename(\n",
    "    columns={'mean':'avg_clv_4w', 'median':'median_clv_4w','count':'num_customers'}\n",
    ")\n",
    "\n",
    "print(\"CLV by cluster:\")\n",
    "print(cluster_clv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
